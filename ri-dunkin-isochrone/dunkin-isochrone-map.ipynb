{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by: [SmirkyGraphs](https://smirkygraphs.github.io/). Code: [Github](https://github.com/SmirkyGraphs/Python-Notebooks). Source: [Dunkin'](https://www.dunkindonuts.com/en/locations) | [HERE API](https://developer.here.com/).\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dunkin' Isochrone Map\n",
    "\n",
    "It's been over 2 years since my reddit [Distance to Nearest Dunkin'](https://www.reddit.com/r/dataisbeautiful/comments/aqw7lu/oc_ri_distance_to_nearest_dunkin/) post and i've been looking for a geo related Python project. So I decided to revisit and update it to address some of the issues with my first map that people pointed out.\n",
    "\n",
    "The biggest issue/feedback people had with my first map was the \"as the crow flies\" distance useage. Meaning the mile circles ignored any road paths, lack of bridges (Prudence Island) or any other obstacles. Using isolines eliminates this issue as it shows drive time going to the Dunkin' and adheres to roadways.\n",
    "\n",
    "Next, a lot of people pointed out the lack of points from Dunkin's just over the state boundary line. To resolve this, I made a rough trace around the state and buffered it to grab any Dunkin' within 5 miles of Rhode Island to also grabbed the isolines for them.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import flexpolyline\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isoline_urls(df, time_range, tranport):\n",
    "    coded_range = ','.join(str(x) for x in time_range)\n",
    "    \n",
    "    urls = {}\n",
    "    for key, lat, lng in zip(df['key'], df['fields.lat'], df['fields.lng']):\n",
    "        url = \"https://isoline.router.hereapi.com/v8/isolines?\" + \\\n",
    "             f\"apiKey={api_key}\" + \\\n",
    "             f\"&range[type]=time\" + \\\n",
    "             f\"&range[values]={coded_range}\" + \\\n",
    "             f\"&transportMode={transport_type}\" + \\\n",
    "             f\"&destination={lat},{lng}\"\n",
    "\n",
    "        urls[key] = url\n",
    "        \n",
    "    return urls\n",
    "\n",
    "def isoline_response(key, url):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "    \n",
    "    cols = ['id','store_key', 'location_lng', 'location_lat', 'seconds', 'geometry']\n",
    "    gdf = gpd.GeoDataFrame(columns=cols, crs=\"EPSG:4326\")\n",
    "    lat = data['arrival']['place']['originalLocation']['lat']\n",
    "    lng = data['arrival']['place']['originalLocation']['lng']\n",
    "    \n",
    "    for i, poly in enumerate(data['isolines']):\n",
    "        seconds = (poly['range']['value'])\n",
    "        polygon = poly['polygons'][0]['outer']\n",
    "        geom = flexpolyline.decode(polygon)\n",
    "        reverse_geom = [(xy[1], xy[0]) for xy in geom]\n",
    "        gdf.loc[i] = [i, key, lng, lat, seconds, reverse_geom]\n",
    "        \n",
    "    return gdf\n",
    "\n",
    "def collect_isolines(df, api_key, time_range, transport_type, sleep):\n",
    "    # filter for already collected keys\n",
    "    files = list(Path('./data/raw/').glob('*.geojson'))\n",
    "    collected_keys = [x.stem for x in files]\n",
    "    df = df[~df['key'].isin(collected_keys)]\n",
    "    \n",
    "    isolines = isoline_urls(df, time_range, transport_type)\n",
    "    \n",
    "    frames = []\n",
    "    for key, url in isolines.items():\n",
    "        gdf = isoline_response(key, url)\n",
    "        gdf['geometry'] = gdf['geometry'].apply(Polygon)\n",
    "\n",
    "        frames.append(gdf)\n",
    "        gdf.to_file(f\"./data/raw/{key}.geojson\", driver='GeoJSON')\n",
    "        time.sleep(sleep)\n",
    "    \n",
    "    return pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "api_key = config['api_key']\n",
    "\n",
    "time_range = [150, 300, 600, 900]\n",
    "transport_type = 'car'\n",
    "\n",
    "df = pd.read_csv('./data/files/ri_dunkins.csv')\n",
    "gdf = collect_isolines(df, api_key, time_range, transport_type, 5)\n",
    "gdf.to_file(\"./data/clean/combined.geojson\", driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
