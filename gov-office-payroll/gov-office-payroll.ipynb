{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by: [SmirkyGraphs](https://smirkygraphs.github.io/). Code: [Github](https://github.com/SmirkyGraphs/Python-Notebooks). Source: [transparency.ri.gov](http://www.transparency.ri.gov/payroll/).\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Governor's Office Change\n",
    "\n",
    "This Notebook contains code releated to the data cleaning for a breakdown of payroll changes in the 2 most recent months of the Governor's Office, during the transition from Gina Raimondo to Daniel McKee. The data is released quarterly, so this consists of data from January 2021, and April 2021. One issue with the data is inconsistant labeling of terminations, there was 3 employees who were terminated last quarter but the termination was removed, however the \"total\" pay change during the period was 0. This was handeled with the `fill_terminated` function which fills terminations with the prior quarter.\n",
    "\n",
    "Another issue with the states payroll data is it lacks any sort of `employee_id` or a key to compare data over fiscal year, or quarter. To deal with this I created a `uid` columns which is `\"first\" + \"m\" + \"last\"`, while this works fine for a tiny < 100 persons governors office, i'm sure would cause duplicates in full payroll data of every department.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "def start_pipeline(df):\n",
    "    return df.copy()\n",
    "\n",
    "def clean_columns(df):\n",
    "    cols = [x.strip() for x in list(df)]\n",
    "    df.columns = cols\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def unique_name_key(df):\n",
    "    \"\"\"\n",
    "    without any sort of \"employee id\" or key to lookup, the best we have is\n",
    "    labeling people by first-m-last name. This works fine for just the GO, \n",
    "    however when used with all departments you run into some duplicates. \n",
    "    \"\"\"\n",
    "    df['uid'] = df['first'] + df['m'] + df['last']\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def add_new_hires(df, clean_old=None):\n",
    "    \"\"\"\n",
    "    last_quarter: all employees last quarter\n",
    "    holdover:     a employee that started last quarter and is still on in recent quarter\n",
    "    new:          a employee that started in the most recent quarter\n",
    "    \"\"\"\n",
    "    if clean_old is None:\n",
    "        df['period'] = 'last_quarter'\n",
    "        return df\n",
    "    else:\n",
    "        holdover = [x for x in df['uid'].tolist() if x in clean_old['uid'].tolist()]\n",
    "        new = [x for x in df['uid'].tolist() if x not in clean_old['uid'].tolist()]\n",
    "        \n",
    "        df.loc[df['uid'].isin(holdover), 'period'] = 'holdover'\n",
    "        df.loc[df['uid'].isin(new), 'period'] = 'new'\n",
    "        \n",
    "        return df\n",
    "    \n",
    "def clean_column_names(df):\n",
    "    cols = ['department', 'title', 'uid', '', 'termination']\n",
    "    for col in cols:\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].replace(r'^\\s+$', np.nan, regex=True)\n",
    "        df[col] = df[col].replace('', np.nan)\n",
    "        \n",
    "    return df\n",
    "    \n",
    "    \n",
    "def remove_columns(df):\n",
    "    remove = ['first', 'm', 'last']\n",
    "    df = df.drop(columns=remove)\n",
    "    \n",
    "    remove = ['regular', 'overtime', 'other']\n",
    "    df = df.drop(columns=remove).dropna(how='all', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def order_columns(df):\n",
    "    cols = [\n",
    "        'uid',\n",
    "        'title',\n",
    "        'department',\n",
    "        'total',\n",
    "        'annual',\n",
    "        'period',\n",
    "        'fiscal_year',\n",
    "        'date_scraped'\n",
    "    ]\n",
    "    \n",
    "    if 'termination' in list(df):\n",
    "        cols.insert(3, 'termination')\n",
    "    \n",
    "    return df[cols].sort_values(by='annual', ascending=False)\n",
    "    \n",
    "\n",
    "def clean_raw_pipeline(df, old_ids=None):\n",
    "    return (df\n",
    "        .pipe(start_pipeline)\n",
    "        .pipe(clean_columns)\n",
    "        .pipe(unique_name_key)\n",
    "        .pipe(clean_column_names)\n",
    "        .pipe(add_new_hires, old_ids)\n",
    "        .pipe(remove_columns)\n",
    "        .pipe(order_columns)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df.copy()\n",
    "\n",
    "def fill_terminated(df):\n",
    "    \"\"\"\n",
    "    For some reason a few people that were terminated last quarter were no longer listed\n",
    "    as terminated. However their \"total\" pay hasn't changed so we fill the termination date\n",
    "    with last quarters date.\n",
    "    \"\"\"\n",
    "    df['termination'] = df.groupby(['uid'])['termination'].fillna(method='ffill')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_merged_pipeline(df):\n",
    "    return (df\n",
    "        .pipe(start_pipeline)\n",
    "        .pipe(fill_terminated)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gina_df = pd.read_csv('./data/raw/gina_exit.csv', parse_dates=['date_scraped'])\n",
    "mckee_df = pd.read_csv('./data/raw/mckee.csv', parse_dates=['date_scraped'])\n",
    "\n",
    "gina = clean_raw_pipeline(gina_df)\n",
    "mckee = clean_raw_pipeline(mckee_df, gina)\n",
    "\n",
    "combined = pd.concat([gina, mckee])\n",
    "df = clean_merged_pipeline(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gina stats\n",
    "gina_stats = df[(df['period']=='last_quarter') & (df['termination'].isnull())]\n",
    "\n",
    "gina_stats = {\n",
    "    \"total_employees\": gina_stats.shape[0],\n",
    "    \"highest_paid\": gina_stats['annual'].max(),\n",
    "    \"total_annual\": gina_stats['annual'].sum(),\n",
    "    \"median_annual\": gina_stats['annual'].median(),\n",
    "    \"missing_title\": gina_stats['title'].isnull().sum()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mckee new employees\n",
    "new_hire = df[(df['period']=='new')]\n",
    "new_hire = new_hire[['uid', 'title', 'annual', 'period', 'date_scraped']]\n",
    "\n",
    "# mckee terminated\n",
    "termination = df[(df['period']!='last_quarter') & (df['termination'].notnull())].copy()\n",
    "termination['termination'] = pd.to_datetime(termination['termination'])\n",
    "\n",
    "termination.loc[termination['termination'] < '2021-03-02', 'termination_when'] = 'br'\n",
    "termination.loc[termination['termination'] == '2021-03-02', 'termination_when'] = 'r'\n",
    "termination.loc[termination['termination'] > '2021-03-02', 'termination_when'] = 'ar'\n",
    "\n",
    "termination = termination.sort_values(by='termination')\n",
    "termination = termination[['uid', 'title', 'annual', 'termination', 'termination_when', 'date_scraped']]\n",
    "\n",
    "# mckee stats\n",
    "mckee_stats = df[(df['period']!='last_quarter') & (df['termination'].isnull())]\n",
    "\n",
    "mckee_stats = {\n",
    "    \"total_employees\": mckee_stats.shape[0],\n",
    "    \"highest_paid\": mckee_stats['annual'].max(),\n",
    "    \"total_annual\": mckee_stats['annual'].sum(),\n",
    "    \"median_annual\": mckee_stats['annual'].median(),\n",
    "    \"missing_title\": mckee_stats['title'].isnull().sum()\n",
    "}\n",
    "\n",
    "stats_df = pd.DataFrame({\"mckee\": mckee_stats, \"gina\": gina_stats}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raises\n",
    "df_raises = df[df['termination'].isnull()]\n",
    "df_raises = df_raises.groupby(['uid', 'date_scraped'])['annual'].sum()\n",
    "diff = df_raises.groupby(['uid']).diff()\n",
    "pct_diff = df_raises.groupby(['uid']).pct_change()\n",
    "\n",
    "raises = pd.concat([df_raises, diff, pct_diff], axis=1)\n",
    "raises.columns = ['current_annual', 'difference', '%_diff']\n",
    "\n",
    "# get table of holdovers pay change\n",
    "raises = (raises\n",
    "    .groupby('uid')\n",
    "    .filter(lambda x: len(x) == 2)\n",
    "    .dropna(axis=0, how='any')\n",
    "    .reset_index()\n",
    "    .sort_values(by='difference', ascending=False)\n",
    ")\n",
    "\n",
    "# make pretty tables\n",
    "raises_table = raises.drop(columns=['date_scraped'])\n",
    "gina_merge = gina[['uid', 'annual']].rename(columns={\"annual\": \"prior_quarter\"})\n",
    "raises_table = raises_table.merge(gina_merge, on='uid')\n",
    "\n",
    "cols = list(raises_table)\n",
    "cols.remove('prior_quarter')\n",
    "cols.insert(1, 'prior_quarter')\n",
    "raises_table = raises_table[cols]\n",
    "\n",
    "no_raise = raises_table[raises_table['difference'] == 0]\n",
    "increased = raises_table[raises_table['difference'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/clean/all_data_extract.csv', index=False)\n",
    "stats_df.to_csv('./data/clean/summary_stats.csv')\n",
    "increased.to_csv('./data/clean/pay_increased.csv', index=False)\n",
    "no_raise.to_csv('./data/clean/no_raise.csv', index=False)\n",
    "termination.to_csv('./data/clean/termination.csv', index=False)\n",
    "new_hire.to_csv('./data/clean/new_hire.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
