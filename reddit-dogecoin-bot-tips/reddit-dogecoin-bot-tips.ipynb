{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903c7db8",
   "metadata": {},
   "source": [
    "Created by [SmirkyGraphs](https://smirkygraphs.github.io/). Code: [Github](https://github.com/SmirkyGraphs/Python-Notebooks). Source: [/u/sodogetip](https://www.reddit.com/u/sodogetip).\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3523cb",
   "metadata": {},
   "source": [
    "# /u/SoDogeTip - Dogecoin Tipping Bot\n",
    "\n",
    "The subreddit /r/dogecoin has a bot ([/u/sodogetip](https://www.reddit.com/user/sodogetip) created by [/u/just-a-dev](https://www.reddit.com/user/just-an-dev)) which users can send a command to tip someone a specific amount of dogecoins. If a user doesn't claim the value within a specific number of days the, the coins go back to the original owner. This code will clean and analyze all comments that were collected from using the [PRAW](https://praw.readthedocs.io/en/stable/index.html) and [Pushshift.io](https://pushshift.io/) API. \n",
    "\n",
    "The tip bot comments in a specific format of `/u/sender -> /u/reciever 0.0 doge ($0.00)`\n",
    "\n",
    "Pushshift was used because PRAW limits the number of available comments of a specific user to only 1,000 (new or top). In total the script collected ~14,000 comment ids between pushshift + praw. There was a few removed comments and 62 that didn't follow the typical format used and wern't parsed correctly (some of these were register/help messages by the bot).\n",
    "\n",
    "I have no affiliation with, or ever used the bot (sodogetip), dev (just-a-dev), or the /r/dogecoin community. I was looking for something to make using PRAW and figured this might be an interesting project given how much news coverage the crypto coin has gotten in the past year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0b1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0094619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "def parse_comment(comment):\n",
    "    if comment['body_string'] == '[removed]':\n",
    "        return 'n/a'\n",
    "    \n",
    "    soup = BeautifulSoup(comment['body_html'], 'lxml')\n",
    "    links = [x['href'] for x in soup.find_all(href=True)]\n",
    "    value = [x.get_text() for x in soup.find_all('strong')]\n",
    "    \n",
    "    try:\n",
    "        data = {\n",
    "            \"comment_id\": comment['comment_id'].lower(),\n",
    "            \"tipper\": links[0].lower(),\n",
    "            \"reciever\": links[1].lower(),\n",
    "            \"num_coins\": value[1].replace('√ê', ''),\n",
    "            \"value_usd\": value[3],\n",
    "            'transaction_id': links[3]\n",
    "        }\n",
    "\n",
    "        return data\n",
    "    except:\n",
    "        errors.append(comment['comment_id'])\n",
    "        \n",
    "def is_tx_spent(tx_id):\n",
    "    api_url = 'https://chain.so/api/v2/is_tx_spent/DOGE'\n",
    "    r = requests.get(f'{api_url}/{tx_id}/0')\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        return r.json()['data']['is_spent']\n",
    "    \n",
    "def is_tx_confirmed(tx_id):\n",
    "    api_url = 'https://chain.so/api/v2/is_tx_confirmed/DOGE'\n",
    "    r = requests.get(f'{api_url}/{tx_id}/')\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        return r.json()['data']['is_confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b42d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/raw/comments.csv', parse_dates=['comment_datetime'])\n",
    "\n",
    "# filter out removed comments\n",
    "df = df[df['body_string'] != '[removed]']\n",
    "\n",
    "# parse body_html for values & names\n",
    "df['parsed'] = df.apply(parse_comment, axis=1)\n",
    "parsed = df['parsed'].apply(pd.Series)\n",
    "\n",
    "# merge parsed to the regular dataframe\n",
    "df = df.merge(parsed, how='left', on='comment_id')\n",
    "df = df.drop(columns=['parsed']).dropna(subset=['value_usd'], axis=0)\n",
    "\n",
    "# clean transaction_id (remove web address)\n",
    "df['transaction_id'] = df['transaction_id'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "# replace values\n",
    "df['value_usd'] = df['value_usd'].str.replace('[$()]', '', regex=True)\n",
    "df = df[~df['value_usd'].str.contains('[abcdefghijklmnopqrstuvwxyz]', regex=True)]\n",
    "df[['value_usd', 'num_coins']] = df[['value_usd', 'num_coins']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d19a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top tippers value\n",
    "top_value = df.groupby('tipper')['value_usd'].agg(['sum', 'size']).sort_values(by='sum', ascending=False).head()\n",
    "top_value.to_csv('./data/clean/top_tippers_usd.csv', index=False)\n",
    "\n",
    "# top tippers coins\n",
    "top_coin = df.groupby('tipper')['num_coins'].agg(['sum', 'size']).sort_values(by='sum', ascending=False).head()\n",
    "top_coin.to_csv('./data/clean/top_tippers_coins.csv', index=False)\n",
    "\n",
    "# top recievers value\n",
    "top_value_rec = df.groupby('reciever')['value_usd'].agg(['sum', 'size']).sort_values(by='sum', ascending=False).head()\n",
    "top_value_rec.to_csv('./data/clean/top_reciever_usd.csv', index=False)\n",
    "\n",
    "# top reciever coins\n",
    "top_coins_rec = df.groupby('tipper')['num_coins'].agg(['sum', 'size']).sort_values(by='sum', ascending=False).head()\n",
    "top_coins_rec.to_csv('./data/clean/top_reciever_coins.csv', index=False)\n",
    "\n",
    "# largest coin transactions\n",
    "cols = ['submission_id', 'comment_id', 'comment_datetime', 'tipper', 'reciever', 'num_coins', 'value_usd']\n",
    "single_most_coins = df[cols].sort_values(by='num_coins', ascending=False).head()\n",
    "single_most_coins.to_csv('./data/clean/single_most_coins.csv', index=False)\n",
    "\n",
    "# largest valued transactions\n",
    "cols = ['submission_id', 'comment_id', 'comment_datetime', 'tipper', 'reciever', 'num_coins', 'value_usd']\n",
    "single_most_values = df[cols].sort_values(by='value_usd', ascending=False).head()\n",
    "single_most_values.to_csv('./data/clean/single_most_values.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
